/**
 * AC FIXBOT - Procesador en Background
 * Ejecuta tareas pesadas de forma as√≠ncrona sin bloquear el webhook
 */

const whatsapp = require('../external/whatsappService');
const vision = require('../ai/visionService');
const aiService = require('../ai/aiService');
const db = require('../storage/databaseService');
const blobService = require('../storage/blobService');
const imageProcessor = require('./imageProcessor');
const MSG = require('../../../bot/constants/messages');
const { ESTADO, ORIGEN_ACCION, TIPO_REPORTE } = require('../../../bot/constants/sessionStates');
const { safeParseJSON } = require('../../utils/helpers');
const { OCRError } = vision;

/**
 * Procesa una imagen en background (OCR + b√∫squeda de equipo)
 * @param {string} from - N√∫mero de tel√©fono del usuario
 * @param {string} imageId - ID de la imagen en WhatsApp
 * @param {Object} context - Contexto de Azure Functions para logs
 */
async function processImageInBackground(from, imageId, context) {
    try {
        context.log(`[Background] Iniciando procesamiento de imagen para ${from}`);

        // 1. Descargar imagen
        const imageBuffer = await whatsapp.downloadMedia(imageId);
        context.log(`[Background] Imagen descargada: ${imageBuffer.length} bytes`);

        // 2. Comprimir y subir imagen a Azure Blob Storage
        let imagenUrl = null;
        try {
            const { buffer: compressedBuffer, originalSize, compressedSize } =
                await imageProcessor.compressImage(imageBuffer);
            context.log(`[Background] Imagen comprimida: ${(originalSize/1024).toFixed(1)}KB ‚Üí ${(compressedSize/1024).toFixed(1)}KB`);

            imagenUrl = await blobService.uploadImage(compressedBuffer, from);
            context.log(`[Background] Imagen subida a Blob Storage: ${imagenUrl}`);
        } catch (uploadError) {
            context.log.warn(`[Background] No se pudo subir imagen a Blob Storage: ${uploadError.message}`);
            // Continuar sin URL de imagen (no es cr√≠tico)
        }

        // 3. Extraer texto con OCR
        let ocrResult;
        try {
            ocrResult = await vision.extractTextFromImage(imageBuffer);
            context.log(`[Background] OCR completado: ${ocrResult.lines.length} l√≠neas`);
        } catch (ocrError) {
            // Manejar errores de OCR con mensajes espec√≠ficos
            if (ocrError instanceof OCRError) {
                context.log(`[Background] ‚ùå Error OCR tipado: ${ocrError.type}`);
                await whatsapp.sendText(from, ocrError.getUserMessage());
                return;
            }
            throw ocrError;
        }

        // 3. Buscar c√≥digo SAP
        const codigoSAP = vision.findSAPCode(ocrResult.lines);

        if (codigoSAP) {
            context.log(`[Background] ‚úÖ C√≥digo SAP detectado: ${codigoSAP}`);

            // 4. Buscar equipo en BD
            const equipo = await db.getEquipoBySAP(codigoSAP);

            if (equipo) {
                // Equipo encontrado - obtener sesi√≥n actual para preservar datosTemp
                const session = await db.getSession(from);
                const datosTemp = safeParseJSON(session.DatosTemp) || {};

                // DEBUG: Log de datosTemp antes de agregar imagenUrl
                context.log(`[Background] datosTemp ANTES: ${JSON.stringify(datosTemp)}`);

                // Agregar URL de imagen a datosTemp
                if (imagenUrl) {
                    datosTemp.imagenUrl = imagenUrl;
                    context.log(`[Background] ‚úÖ imagenUrl agregada a datosTemp: ${imagenUrl}`);
                } else {
                    context.log(`[Background] ‚ö†Ô∏è imagenUrl es NULL, no se agregar√° a datosTemp`);
                }

                // DEBUG: Log de datosTemp despu√©s de agregar imagenUrl
                context.log(`[Background] datosTemp DESPU√âS: ${JSON.stringify(datosTemp)}`);

                // Actualizar sesi√≥n preservando datosTemp con la imagen
                await db.updateSession(
                    from,
                    ESTADO.REFRI_CONFIRMAR_EQUIPO,
                    datosTemp,
                    equipo.EquipoId,
                    ORIGEN_ACCION.BOT,
                    `Equipo detectado por OCR: ${equipo.CodigoSAP}`
                );

                context.log(`[Background] ‚úÖ Sesi√≥n actualizada con datosTemp que incluye imagenUrl`);

                await whatsapp.sendInteractiveMessage(
                    from,
                    '‚úÖ C√≥digo Detectado',
                    `‚Ä¢ *C√≥digo SAP:* ${equipo.CodigoSAP}\n` +
                    `‚Ä¢ *Modelo:* ${equipo.Modelo}\n` +
                    `‚Ä¢ *Marca:* ${equipo.Marca || 'N/A'}\n` +
                    `‚Ä¢ *Cliente:* ${equipo.NombreCliente}\n` +
                    `‚Ä¢ *Ubicaci√≥n:* ${equipo.Ubicacion || 'N/A'}\n\n` +
                    '¬øLa informaci√≥n del equipo es correcta?',
                    [
                        MSG.BUTTONS.CONFIRMAR_EQUIPO,
                        MSG.BUTTONS.CORREGIR_EQUIPO,
                        MSG.BUTTONS.CANCELAR
                    ]
                );
            } else {
                // C√≥digo detectado pero equipo no encontrado
                await whatsapp.sendText(from,
                    `üîç Detect√© el c√≥digo *${codigoSAP}* en la imagen,\n` +
                    'pero no encontr√© ning√∫n equipo registrado con ese n√∫mero.\n\n' +
                    '¬øPodr√≠as verificar que el c√≥digo es correcto e intentar de nuevo?'
                );
            }
        } else {
            // Texto encontrado pero sin c√≥digo SAP v√°lido
            context.log('[Background] ‚ùå No se encontr√≥ c√≥digo SAP en el texto extra√≠do');
            const linesPreview = ocrResult.lines.slice(0, 3).join(', ');
            context.log(`[Background] Texto encontrado: ${linesPreview}...`);

            await whatsapp.sendText(from,
                'üîç Analic√© la imagen pero no encontr√© un c√≥digo SAP v√°lido.\n\n' +
                '*El c√≥digo SAP debe tener 7 d√≠gitos num√©ricos.*\n\n' +
                '*Sugerencias:*\n' +
                '‚Ä¢ Aseg√∫rate de que el c√≥digo de barras est√© completo en la imagen\n' +
                '‚Ä¢ Los n√∫meros debajo del c√≥digo deben ser legibles\n' +
                '‚Ä¢ Evita sombras o reflejos sobre el c√≥digo\n\n' +
                'Tambi√©n puedes ingresar el c√≥digo SAP manualmente (7 d√≠gitos).'
            );
        }

        context.log(`[Background] ‚úÖ Procesamiento completado para ${from}`);

    } catch (error) {
        context.log.error('[Background] ‚ùå Error procesando imagen:', error);

        // Si es un OCRError que no fue manejado antes
        if (error instanceof OCRError) {
            await whatsapp.sendText(from, error.getUserMessage());
        } else {
            await whatsapp.sendText(from,
                '‚ùå Hubo un problema al procesar la imagen.\n\n' +
                '*Sugerencias:*\n' +
                '‚Ä¢ Verifica que la imagen no est√© corrupta\n' +
                '‚Ä¢ Intenta enviar una nueva foto\n\n' +
                'Tambi√©n puedes ingresar el c√≥digo SAP manualmente (7 d√≠gitos).'
            );
        }
    }
}

/**
 * Procesa una imagen con AI Vision en background (extracci√≥n de datos con IA)
 * @param {string} from - N√∫mero de tel√©fono del usuario
 * @param {string} imageId - ID de la imagen en WhatsApp
 * @param {string} caption - Texto opcional que acompa√±√≥ la imagen
 * @param {Object} context - Contexto de Azure Functions para logs
 */
async function processImageWithAIVision(from, imageId, caption, context) {
    try {
        context.log(`[Background AI Vision] Iniciando an√°lisis de imagen para ${from}`);

        // 1. Descargar imagen
        const imageBuffer = await whatsapp.downloadMedia(imageId);
        context.log(`[Background AI Vision] Imagen descargada: ${imageBuffer.length} bytes`);

        // 2. Comprimir y subir imagen a Azure Blob Storage
        let imagenUrl = null;
        try {
            const { buffer: compressedBuffer, originalSize, compressedSize } =
                await imageProcessor.compressImage(imageBuffer);
            context.log(`[Background AI Vision] Imagen comprimida: ${(originalSize/1024).toFixed(1)}KB ‚Üí ${(compressedSize/1024).toFixed(1)}KB`);

            imagenUrl = await blobService.uploadImage(compressedBuffer, from);
            context.log(`[Background AI Vision] Imagen subida a Blob Storage: ${imagenUrl}`);
        } catch (uploadError) {
            context.log.warn(`[Background AI Vision] No se pudo subir imagen a Blob Storage: ${uploadError.message}`);
        }

        // 3. Analizar imagen con AI Vision
        context.log(`[Background AI Vision] Analizando imagen con AI...`);
        const analisisAI = await aiService.analyzeImageWithVision(imageBuffer, caption);
        context.log(`[Background AI Vision] An√°lisis completado:`, JSON.stringify(analisisAI));

        // 4. Obtener sesi√≥n actual
        const session = await db.getSession(from);
        const datosTemp = safeParseJSON(session.DatosTemp) || {};

        // 5. Agregar URL de imagen a datosTemp
        if (imagenUrl) {
            datosTemp.imagenUrl = imagenUrl;
            context.log(`[Background AI Vision] imagenUrl agregada a datosTemp`);
        }

        // 6. Enriquecer datosTemp con datos extra√≠dos de la imagen
        let codigoDetectado = false;
        let empleadoDetectado = false;
        let problemaDetectado = false;

        if (analisisAI.codigo_sap && analisisAI.confianza > 50) {
            // Para veh√≠culos usamos codigoSAPVehiculo
            if (datosTemp.tipoReporte === TIPO_REPORTE.VEHICULO) {
                datosTemp.codigoSAPVehiculo = analisisAI.codigo_sap;
                context.log(`[Background AI Vision] C√≥digo SAP Veh√≠culo detectado: ${analisisAI.codigo_sap}`);
            } else {
                datosTemp.codigoSAP = analisisAI.codigo_sap;
                context.log(`[Background AI Vision] C√≥digo SAP detectado: ${analisisAI.codigo_sap}`);
            }
            codigoDetectado = true;
        }

        if (analisisAI.numero_empleado) {
            datosTemp.numeroEmpleado = analisisAI.numero_empleado;
            context.log(`[Background AI Vision] N√∫mero de empleado detectado: ${analisisAI.numero_empleado}`);
            empleadoDetectado = true;
        }

        if (analisisAI.problema) {
            // Para veh√≠culos usamos problemaTemp
            if (datosTemp.tipoReporte === TIPO_REPORTE.VEHICULO) {
                datosTemp.problemaTemp = analisisAI.problema;
            } else {
                datosTemp.problema = analisisAI.problema;
            }
            context.log(`[Background AI Vision] Problema detectado: ${analisisAI.problema}`);
            problemaDetectado = true;
        }

        // 7. Guardar informaci√≥n visual para referencia
        if (analisisAI.informacion_visual) {
            datosTemp.informacionVisual = analisisAI.informacion_visual;
        }

        // 8. Determinar tipo de equipo si no est√° definido
        if (!datosTemp.tipoReporte && analisisAI.tipo_equipo) {
            if (analisisAI.tipo_equipo === 'REFRIGERADOR') {
                datosTemp.tipoReporte = TIPO_REPORTE.REFRIGERADOR;
            } else if (analisisAI.tipo_equipo === 'VEHICULO') {
                datosTemp.tipoReporte = TIPO_REPORTE.VEHICULO;
            }
        }

        // 9. Determinar el nuevo estado seg√∫n los datos extra√≠dos
        let nuevoEstado = session.Estado;

        // Si detectamos datos de veh√≠culo y hay informaci√≥n √∫til, pedir confirmaci√≥n
        if (datosTemp.tipoReporte === TIPO_REPORTE.VEHICULO && (codigoDetectado || empleadoDetectado || problemaDetectado)) {
            nuevoEstado = ESTADO.VEHICULO_CONFIRMAR_DATOS_AI;
            context.log(`[Background AI Vision] Cambiando estado a VEHICULO_CONFIRMAR_DATOS_AI para confirmaci√≥n`);
        }

        // Actualizar sesi√≥n con los datos extra√≠dos y nuevo estado
        await db.updateSession(
            from,
            nuevoEstado,
            datosTemp,
            session.EquipoIdTemp,
            ORIGEN_ACCION.BOT,
            'Datos extra√≠dos de imagen con AI Vision'
        );

        // 10. Construir mensaje de respuesta
        let mensaje = 'ü§ñ *An√°lisis de imagen completado*\n\n';

        if (analisisAI.informacion_visual) {
            mensaje += `üì∑ *Lo que veo:* ${analisisAI.informacion_visual}\n\n`;
        }

        const datosDetectados = [];
        if (analisisAI.codigo_sap) {
            datosDetectados.push(`‚Ä¢ C√≥digo SAP: *${analisisAI.codigo_sap}*`);
        }
        if (analisisAI.numero_empleado) {
            datosDetectados.push(`‚Ä¢ N√∫mero de empleado: *${analisisAI.numero_empleado}*`);
        }
        if (analisisAI.problema) {
            datosDetectados.push(`‚Ä¢ Problema: *${analisisAI.problema}*`);
        }
        if (analisisAI.codigos_visibles && analisisAI.codigos_visibles.length > 0) {
            datosDetectados.push(`‚Ä¢ C√≥digos visibles: ${analisisAI.codigos_visibles.join(', ')}`);
        }

        if (datosDetectados.length > 0) {
            mensaje += '*Informaci√≥n detectada:*\n' + datosDetectados.join('\n') + '\n\n';
            mensaje += '¬øLa informaci√≥n es correcta?';
        } else {
            mensaje += '‚ö†Ô∏è No pude detectar informaci√≥n espec√≠fica en la imagen.\n\n';
            mensaje += 'Por favor, proporciona los datos manualmente o intenta con una imagen m√°s clara.';
        }

        await whatsapp.sendText(from, mensaje);

        context.log(`[Background AI Vision] ‚úÖ Procesamiento completado para ${from}`);

    } catch (error) {
        context.log.error('[Background AI Vision] ‚ùå Error procesando imagen:', error);
        await whatsapp.sendText(from,
            '‚ùå Hubo un problema al analizar la imagen.\n\n' +
            'Por favor, intenta nuevamente o proporciona los datos manualmente.'
        );
    }
}

module.exports = {
    processImageInBackground,
    processImageWithAIVision
};
